{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f80622-35b3-4002-bf37-9a7e7b9c1446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.cores': '1', 'spark.executor.memory': '2g', 'spark.driver.memory': '4g', 'spark.sql.shuffle.partitions': '8'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>772</td><td>application_1765289937462_0765</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0765/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0765_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>774</td><td>application_1765289937462_0767</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0767/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0767_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>789</td><td>application_1765289937462_0782</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0782/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0782_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>791</td><td>application_1765289937462_0784</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0784/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0784_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"conf\": {\n",
    "    \"spark.executor.instances\": \"4\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.executor.memory\": \"2g\",\n",
    "    \"spark.driver.memory\": \"4g\",\n",
    "    \"spark.sql.shuffle.partitions\": \"8\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b09613-2ab0-4072-9991-fa04483891f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>801</td><td>application_1765289937462_0794</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0794/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0794_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047011cf74044a1ab0912b854a8d18cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623be8de6ac74666a589f0a5fa8fdad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "Loading crime data & RE codes as DataFrames...\n",
      "[INFO] Data loading + union: 3.35 sec\n",
      "====================================================================\n",
      "DF pipeline for Query 2 (per year, top-3 Vict Descent)...\n",
      "+----+----------------------+-----------+----------+\n",
      "|year|Victim_Descent        |num_victims|percentage|\n",
      "+----+----------------------+-----------+----------+\n",
      "|2010|Hispanic/Latin/Mexican|73558      |38.93     |\n",
      "|2010|White                 |53835      |28.49     |\n",
      "|2010|Black                 |33937      |17.96     |\n",
      "|2011|Hispanic/Latin/Mexican|70845      |38.8      |\n",
      "|2011|White                 |51219      |28.05     |\n",
      "|2011|Black                 |32579      |17.84     |\n",
      "|2012|Hispanic/Latin/Mexican|70338      |38.25     |\n",
      "|2012|White                 |51839      |28.19     |\n",
      "|2012|Black                 |33572      |18.26     |\n",
      "|2013|Hispanic/Latin/Mexican|66741      |37.97     |\n",
      "|2013|White                 |48453      |27.57     |\n",
      "|2013|Black                 |31975      |18.19     |\n",
      "|2014|Hispanic/Latin/Mexican|68763      |38.42     |\n",
      "|2014|White                 |47531      |26.56     |\n",
      "|2014|Black                 |32952      |18.41     |\n",
      "|2015|Hispanic/Latin/Mexican|55978      |36.65     |\n",
      "|2015|White                 |44102      |28.87     |\n",
      "|2015|Black                 |26510      |17.35     |\n",
      "|2016|Hispanic/Latin/Mexican|99135      |38.74     |\n",
      "|2016|White                 |63760      |24.92     |\n",
      "|2016|Black                 |42449      |16.59     |\n",
      "|2017|Hispanic/Latin/Mexican|78308      |37.55     |\n",
      "|2017|White                 |52744      |25.29     |\n",
      "|2017|Black                 |34713      |16.65     |\n",
      "|2018|Hispanic/Latin/Mexican|75958      |36.42     |\n",
      "|2018|White                 |52233      |25.05     |\n",
      "|2018|Black                 |35340      |16.95     |\n",
      "|2019|Hispanic/Latin/Mexican|72458      |36.38     |\n",
      "|2019|White                 |48863      |24.54     |\n",
      "|2019|Black                 |33157      |16.65     |\n",
      "|2020|Hispanic/Latin/Mexican|61606      |35.33     |\n",
      "|2020|White                 |42638      |24.45     |\n",
      "|2020|Black                 |28785      |16.51     |\n",
      "|2021|Hispanic/Latin/Mexican|63676      |35.08     |\n",
      "|2021|White                 |44523      |24.53     |\n",
      "|2021|Black                 |30173      |16.62     |\n",
      "|2022|Hispanic/Latin/Mexican|73111      |35.64     |\n",
      "|2022|White                 |46695      |22.76     |\n",
      "|2022|Black                 |34634      |16.88     |\n",
      "|2023|Hispanic/Latin/Mexican|69401      |34.55     |\n",
      "|2023|White                 |44615      |22.21     |\n",
      "|2023|Black                 |30504      |15.19     |\n",
      "|2024|Hispanic/Latin/Mexican|28576      |29.05     |\n",
      "|2024|White                 |22958      |23.34     |\n",
      "|2024|Unknown               |19984      |20.32     |\n",
      "|2025|Hispanic/Latin/Mexican|34         |40.48     |\n",
      "|2025|Unknown               |24         |28.57     |\n",
      "|2025|White                 |13         |15.48     |\n",
      "+----+----------------------+-----------+----------+\n",
      "\n",
      "[TIMING] DF Query 2 pipeline: 17.77 sec"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, DoubleType\n",
    "from pyspark.sql.functions import (\n",
    "    col, substring, sum as F_sum, round as F_round, row_number\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "\n",
    "# Paths\n",
    "crime_2010_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\"\n",
    "crime_2020_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "re_codes_path   = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/RE_codes.csv\"\n",
    "\n",
    "# Schema για crime data (όπως στο Query 1)\n",
    "crime_schema = StructType([\n",
    "    StructField(\"DR_NO\",          StringType()),\n",
    "    StructField(\"Date Rptd\",      StringType()),\n",
    "    StructField(\"DATE OCC\",       StringType()),\n",
    "    StructField(\"TIME OCC\",       StringType()),\n",
    "    StructField(\"AREA\",           StringType()),\n",
    "    StructField(\"AREA NAME\",      StringType()),\n",
    "    StructField(\"Rpt Dist No\",    StringType()),\n",
    "    StructField(\"Part 1-2\",       StringType()),\n",
    "    StructField(\"Crm Cd\",         StringType()),\n",
    "    StructField(\"Crm Cd Desc\",    StringType()),\n",
    "    StructField(\"Mocodes\",        StringType()),\n",
    "    StructField(\"Vict Age\",       IntegerType()),\n",
    "    StructField(\"Vict Sex\",       StringType()),\n",
    "    StructField(\"Vict Descent\",   StringType()),\n",
    "    StructField(\"Premis Cd\",      StringType()),\n",
    "    StructField(\"Premis Desc\",    StringType()),\n",
    "    StructField(\"Weapon Used Cd\", StringType()),\n",
    "    StructField(\"Weapon Desc\",    StringType()),\n",
    "    StructField(\"Status\",         StringType()),\n",
    "    StructField(\"Status Desc\",    StringType()),\n",
    "    StructField(\"Crm Cd 1\",       StringType()),\n",
    "    StructField(\"Crm Cd 2\",       StringType()),\n",
    "    StructField(\"Crm Cd 3\",       StringType()),\n",
    "    StructField(\"Crm Cd 4\",       StringType()),\n",
    "    StructField(\"LOCATION\",       StringType()),\n",
    "    StructField(\"Cross Street\",   StringType()),\n",
    "    StructField(\"LAT\",            DoubleType()),\n",
    "    StructField(\"LON\",            DoubleType())\n",
    "])\n",
    "\n",
    "# Schema για RE_codes\n",
    "re_codes_schema = StructType([\n",
    "    StructField(\"Vict Descent\",      StringType()),\n",
    "    StructField(\"Vict Descent Full\", StringType())\n",
    "])\n",
    "\n",
    "# Implementation 1: DataFrame API for Query 2\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DF query 2 execution\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"====================================================================\")\n",
    "print(\"Loading crime data & RE codes as DataFrames...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Διαβάζουμε crime data με explicit schema\n",
    "crime_2010_df = spark.read.format(\"csv\") \\\n",
    "    .options(header=\"true\") \\\n",
    "    .schema(crime_schema) \\\n",
    "    .load(crime_2010_path)\n",
    "\n",
    "crime_2020_df = spark.read.format(\"csv\") \\\n",
    "    .options(header=\"true\") \\\n",
    "    .schema(crime_schema) \\\n",
    "    .load(crime_2020_path)\n",
    "\n",
    "crime_df = crime_2010_df.unionByName(crime_2020_df)\n",
    "\n",
    "# Διαβάζουμε RE_codes (φυλετικά γκρουπ)\n",
    "re_codes_df = spark.read.format(\"csv\") \\\n",
    "    .options(header=\"true\") \\\n",
    "    .schema(re_codes_schema) \\\n",
    "    .load(re_codes_path)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"[INFO] Data loading + union: {t1 - t0:.2f} sec\")\n",
    "#crime_df.show(3, truncate=False)\n",
    "#re_codes_df.show(5, truncate=False)\n",
    "\n",
    "print(\"====================================================================\")\n",
    "print(\"DF pipeline for Query 2 (per year, top-3 Vict Descent)...\")\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "# 1) Εξάγουμε year από DATE OCC (πρώτα 4 ψηφία) και κρατάμε μόνο όσες έχουν Vict Descent\n",
    "crime_with_year_df = crime_df \\\n",
    "    .withColumn(\"year\", substring(col(\"DATE OCC\"), 1, 4).cast(\"int\")) \\\n",
    "    .filter(col(\"year\").isNotNull()) \\\n",
    "    .filter(col(\"Vict Descent\").isNotNull() & (col(\"Vict Descent\") != \"\"))\n",
    "\n",
    "# 2) Group by (year, Vict Descent) και count victims\n",
    "year_descent_counts_df = crime_with_year_df \\\n",
    "    .groupBy(\"year\", \"Vict Descent\") \\\n",
    "    .count()\n",
    "\n",
    "# 3) Σύνολο θυμάτων ανά έτος\n",
    "year_totals_df = year_descent_counts_df \\\n",
    "    .groupBy(\"year\") \\\n",
    "    .agg(F_sum(\"count\").alias(\"total_victims\"))\n",
    "\n",
    "# 4) Join για να υπολογίσουμε ποσοστά\n",
    "with_totals_df = year_descent_counts_df.join(year_totals_df, on=\"year\")\n",
    "\n",
    "with_percent_df = with_totals_df \\\n",
    "    .withColumn(\"percentage\", (col(\"count\") / col(\"total_victims\")) * 100.0)\n",
    "\n",
    "# 5) Join με RE_codes για να πάρουμε full περιγραφή (Vict Descent Full)\n",
    "with_labels_df = with_percent_df.join(\n",
    "    re_codes_df,\n",
    "    on=\"Vict Descent\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 6) Top-3 φυλετικά groups ανά έτος (Window + row_number)\n",
    "w = Window.partitionBy(\"year\").orderBy(col(\"count\").desc())\n",
    "\n",
    "ranked_df = with_labels_df \\\n",
    "    .withColumn(\"rn\", row_number().over(w))\n",
    "\n",
    "top3_per_year_df = ranked_df \\\n",
    "    .filter(col(\"rn\") <= 3) \\\n",
    "    .select(\n",
    "        col(\"year\"),\n",
    "        col(\"Vict Descent Full\").alias(\"Victim_Descent\"),\n",
    "        col(\"count\").alias(\"num_victims\"),\n",
    "        F_round(col(\"percentage\"), 2).alias(\"percentage\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"year\"), col(\"num_victims\").desc())\n",
    "\n",
    "\n",
    "\n",
    "top3_per_year_df.show(60, truncate=False)\n",
    "\n",
    "t3 = time.time()\n",
    "print(f\"[TIMING] DF Query 2 pipeline: {t3 - t2:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d077dbf-a316-4aa3-bb33-2811ae54dc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
