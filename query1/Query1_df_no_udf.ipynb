{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4fc096-b94b-4713-8a2e-aea4e1e53efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.cores': '1', 'spark.executor.memory': '2g', 'spark.driver.memory': '4g'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>664</td><td>application_1765289937462_0657</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0657/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0657_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>666</td><td>application_1765289937462_0659</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0659/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-156.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0659_01_000004/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>667</td><td>application_1765289937462_0660</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0660/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0660_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>668</td><td>application_1765289937462_0661</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0661/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0661_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>669</td><td>application_1765289937462_0662</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0662/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0662_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>671</td><td>application_1765289937462_0664</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0664/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0664_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>672</td><td>application_1765289937462_0665</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0665/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0665_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>673</td><td>application_1765289937462_0666</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0666/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0666_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>687</td><td>application_1765289937462_0680</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0680/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0680_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>690</td><td>application_1765289937462_0683</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0683/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-156.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0683_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>691</td><td>application_1765289937462_0684</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0684/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0684_01_000002/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\" : { \n",
    "        \"spark.executor.instances\" : \"4\" ,\n",
    "        \"spark.executor.cores\" : \"1\" ,\n",
    "        \"spark.executor.memory\" : \"2g\" ,\n",
    "        \"spark.driver.memory\" : \"4g\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6d3aa6-24f8-4bc4-bec9-6d7df87dda73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>692</td><td>application_1765289937462_0685</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0685/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0685_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f4ab8e29f438db4e3487f63dbae78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8497a807d394605ac42f60fb6cd49c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "Loading crime data as DataFrames with explicit schema...\n",
      "[INFO] Data loading + union: 2.88 sec\n",
      "====================================================================\n",
      "Filtering aggravated assaults and computing age groups (no UDF)...\n",
      "+--------------------+------+\n",
      "|age_group           |count |\n",
      "+--------------------+------+\n",
      "|Adults (25-64)      |121660|\n",
      "|Young adults (18-24)|33758 |\n",
      "|Children (<18)      |10904 |\n",
      "|Seniors (>64)       |6011  |\n",
      "+--------------------+------+\n",
      "\n",
      "[TIMING] DF (no UDF) pipeline: 0.15 sec"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, lower, when\n",
    "import time\n",
    "\n",
    "# Paths για τα crime data\n",
    "crime_2010_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\"\n",
    "crime_2020_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "\n",
    "# Schema – ΟΛΕΣ οι στήλες όπως στο sample\n",
    "crime_schema = StructType([\n",
    "    StructField(\"DR_NO\",          StringType()),\n",
    "    StructField(\"Date Rptd\",      StringType()),\n",
    "    StructField(\"DATE OCC\",       StringType()),\n",
    "    StructField(\"TIME OCC\",       StringType()),\n",
    "    StructField(\"AREA\",           StringType()),\n",
    "    StructField(\"AREA NAME\",      StringType()),\n",
    "    StructField(\"Rpt Dist No\",    StringType()),\n",
    "    StructField(\"Part 1-2\",       StringType()),\n",
    "    StructField(\"Crm Cd\",         StringType()),\n",
    "    StructField(\"Crm Cd Desc\",    StringType()),\n",
    "    StructField(\"Mocodes\",        StringType()),\n",
    "    StructField(\"Vict Age\",       IntegerType()),\n",
    "    StructField(\"Vict Sex\",       StringType()),\n",
    "    StructField(\"Vict Descent\",   StringType()),\n",
    "    StructField(\"Premis Cd\",      StringType()),\n",
    "    StructField(\"Premis Desc\",    StringType()),\n",
    "    StructField(\"Weapon Used Cd\", StringType()),\n",
    "    StructField(\"Weapon Desc\",    StringType()),\n",
    "    StructField(\"Status\",         StringType()),\n",
    "    StructField(\"Status Desc\",    StringType()),\n",
    "    StructField(\"Crm Cd 1\",       StringType()),\n",
    "    StructField(\"Crm Cd 2\",       StringType()),\n",
    "    StructField(\"Crm Cd 3\",       StringType()),\n",
    "    StructField(\"Crm Cd 4\",       StringType()),\n",
    "    StructField(\"LOCATION\",       StringType()),\n",
    "    StructField(\"Cross Street\",   StringType()),\n",
    "    StructField(\"LAT\",            DoubleType()),\n",
    "    StructField(\"LON\",            DoubleType())\n",
    "])\n",
    "\n",
    "# Implementation 1: DataFrame API (χωρίς UDF)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DF Query 1 execution (no UDF)\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"====================================================================\")\n",
    "print(\"Loading crime data as DataFrames with explicit schema...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "crime_2010_df = spark.read.format(\"csv\") \\\n",
    "    .options(header=\"true\") \\\n",
    "    .schema(crime_schema) \\\n",
    "    .load(crime_2010_path)\n",
    "\n",
    "crime_2020_df = spark.read.format(\"csv\") \\\n",
    "    .options(header=\"true\") \\\n",
    "    .schema(crime_schema) \\\n",
    "    .load(crime_2020_path)\n",
    "\n",
    "crime_df = crime_2010_df.unionByName(crime_2020_df)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"[INFO] Data loading + union: {t1 - t0:.2f} sec\")\n",
    "#crime_df.printSchema()\n",
    "#crime_df.show(5, truncate=False)\n",
    "\n",
    "print(\"====================================================================\")\n",
    "print(\"Filtering aggravated assaults and computing age groups (no UDF)...\")\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "# Φιλτράρουμε μόνο aggravated assault (case-insensitive)\n",
    "aggravated_df = crime_df.filter(\n",
    "    col(\"Crm Cd Desc\").isNotNull() &\n",
    "    lower(col(\"Crm Cd Desc\")).contains(\"aggravated assault\")\n",
    ")\n",
    "\n",
    "# Φιλτράρουμε ηλικίες (Vict Age > 0)\n",
    "aggr_with_age_df = aggravated_df.filter(\n",
    "    col(\"Vict Age\").isNotNull() & (col(\"Vict Age\") > 0)\n",
    ")\n",
    "\n",
    "# Ορισμός buckets μόνο με built-in expressions\n",
    "age_grouped_df = aggr_with_age_df \\\n",
    "    .withColumn(\n",
    "        \"age_group\",\n",
    "        when(col(\"Vict Age\") < 18, \"Children (<18)\") \\\n",
    "        .when((col(\"Vict Age\") >= 18) & (col(\"Vict Age\") <= 24), \"Young adults (18-24)\") \\\n",
    "        .when((col(\"Vict Age\") >= 25) & (col(\"Vict Age\") <= 64), \"Adults (25-64)\") \\\n",
    "        .otherwise(\"Seniors (>64)\")\n",
    "    ) \\\n",
    "    .groupBy(\"age_group\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc())\n",
    "\n",
    "t3 = time.time()\n",
    "\n",
    "age_grouped_df.show(truncate=False)\n",
    "print(f\"[TIMING] DF (no UDF) pipeline: {t3 - t2:.2f} sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
