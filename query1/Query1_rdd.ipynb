{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5487251-27ee-4f21-9413-560231b0f4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.cores': '1', 'spark.executor.memory': '2g', 'spark.driver.memory': '4g'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>655</td><td>application_1765289937462_0648</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0648/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0648_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>656</td><td>application_1765289937462_0649</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0649/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0649_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>664</td><td>application_1765289937462_0657</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0657/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0657_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>665</td><td>application_1765289937462_0658</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0658/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-156.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0658_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>666</td><td>application_1765289937462_0659</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0659/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-156.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0659_01_000004/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>667</td><td>application_1765289937462_0660</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0660/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0660_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>668</td><td>application_1765289937462_0661</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0661/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0661_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>669</td><td>application_1765289937462_0662</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0662/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0662_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>670</td><td>application_1765289937462_0663</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0663/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0663_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>671</td><td>application_1765289937462_0664</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0664/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0664_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>672</td><td>application_1765289937462_0665</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0665/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0665_01_000002/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\" : { \n",
    "        \"spark.executor.instances\" : \"4\" ,\n",
    "        \"spark.executor.cores\" : \"1\" ,\n",
    "        \"spark.executor.memory\" : \"2g\" ,\n",
    "        \"spark.driver.memory\" : \"4g\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309e0bf2-3b05-4769-84a5-fdff6ae81b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cbfe3a988140c3a3edc3c3fc8eac98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "Loading crime data as RDDs (2010?2019 & 2020?2025)...\n",
      "[INFO] RDD loading + union: 4.16 sec\n",
      "====================================================================\n",
      "RDD pipeline: filter aggravated assaults and count age groups...\n",
      "Adults (25-64): 121660\n",
      "Young adults (18-24): 33758\n",
      "Children (<18): 10904\n",
      "Seniors (>64): 6011\n",
      "[TIMING] RDD pipeline: 14.85 sec\n",
      "===================================================================="
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Paths για τα crime data\n",
    "crime_2010_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\"\n",
    "crime_2020_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "\n",
    "# Implementation 3: RDD API\n",
    "\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"RDD query 1 execution\") \\\n",
    "    .getOrCreate() \\\n",
    "    .sparkContext\n",
    "\n",
    "# ========================================\n",
    "# Load and process data\n",
    "# ========================================\n",
    "\n",
    "print(\"====================================================================\")\n",
    "print(\"Loading crime data as RDDs (2010–2019 & 2020–2025)...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Διαβάζουμε raw text\n",
    "crime_2010_raw = sc.textFile(crime_2010_path)\n",
    "crime_2020_raw = sc.textFile(crime_2020_path)\n",
    "\n",
    "# Παίρνουμε headers (πρώτη γραμμή από κάθε αρχείο)\n",
    "header_2010 = crime_2010_raw.first()\n",
    "header_2020 = crime_2020_raw.first()\n",
    "\n",
    "# Μικρός CSV parser \n",
    "def parse_csv_line(line):\n",
    "    return next(csv.reader([line]))\n",
    "\n",
    "# Σπάμε το header του 2010 σε στήλες\n",
    "header_cols = parse_csv_line(header_2010)\n",
    "\n",
    "# Εντοπίζουμε τα indexes που μας χρειάζονται\n",
    "idx_crm_cd_desc = header_cols.index(\"Crm Cd Desc\")\n",
    "idx_vict_age    = header_cols.index(\"Vict Age\")\n",
    "\n",
    "# Πετάμε τα header rows & κάνουμε parsing κάθε γραμμή\n",
    "crime_2010_rows = crime_2010_raw \\\n",
    "    .filter(lambda line: line != header_2010) \\\n",
    "    .map(parse_csv_line)\n",
    "\n",
    "crime_2020_rows = crime_2020_raw \\\n",
    "    .filter(lambda line: line != header_2020) \\\n",
    "    .map(parse_csv_line)\n",
    "\n",
    "# Ενώνουμε τα δύο RDDs (όπως κάναμε union σε διάφορα παραδείγματα)\n",
    "crime_rdd = crime_2010_rows.union(crime_2020_rows)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"[INFO] RDD loading + union: {t1 - t0:.2f} sec\")\n",
    "\n",
    "print(\"====================================================================\")\n",
    "print(\"RDD pipeline: filter aggravated assaults and count age groups...\")\n",
    "\n",
    "# =======================\n",
    "# Helper functions\n",
    "\n",
    "# =======================\n",
    "\n",
    "def is_aggravated_rdd(row):\n",
    "    \"\"\"\n",
    "    row: list of strings (columns)\n",
    "    Ελέγχουμε Crm Cd Desc (case-insensitive) για 'AGGRAVATED ASSAULT'\n",
    "    \"\"\"\n",
    "    desc = row[idx_crm_cd_desc]\n",
    "    return \"AGGRAVATED ASSAULT\" in desc.upper()\n",
    "\n",
    "def age_group_from_row_rdd(row):\n",
    "    \"\"\"\n",
    "    row: list of strings\n",
    "    Διαβάζουμε Vict Age και επιστρέφουμε age_group\n",
    "    \"\"\"\n",
    "    age_str = row[idx_vict_age]\n",
    "    if age_str == \"\":\n",
    "        return None  # αγνοούμε κενές ηλικίες\n",
    "\n",
    "    a = int(age_str)\n",
    "    if a <= 0:\n",
    "        return None  # ίδιο λογικό φιλτράρισμα με DF (Vict Age > 0)\n",
    "\n",
    "    if a < 18:\n",
    "        return \"Children (<18)\"\n",
    "    elif a <= 24:\n",
    "        return \"Young adults (18-24)\"\n",
    "    elif a <= 64:\n",
    "        return \"Adults (25-64)\"\n",
    "    else:\n",
    "        return \"Seniors (>64)\"\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "# 1) Κρατάμε μόνο aggravated assault\n",
    "aggravated_rdd = crime_rdd.filter(is_aggravated_rdd)\n",
    "\n",
    "# 2) Εξάγουμε age_group ή None\n",
    "age_groups_rdd = aggravated_rdd.map(age_group_from_row_rdd)\n",
    "\n",
    "# 3) Πετάμε τα None\n",
    "valid_age_groups_rdd = age_groups_rdd.filter(lambda g: g is not None)\n",
    "\n",
    "# 4) Μετράμε occurrences ανά age_group (όπως WordCount)\n",
    "age_group_counts_rdd = valid_age_groups_rdd \\\n",
    "    .map(lambda g: (g, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# 5) Ταξινόμηση κατά count φθίνουσα\n",
    "sorted_age_group_counts_rdd = age_group_counts_rdd.sortBy(lambda kv: kv[1], ascending=False)\n",
    "\n",
    "result_rdd = sorted_age_group_counts_rdd.collect()\n",
    "\n",
    "t3 = time.time()\n",
    "\n",
    "for age_group, count in result_rdd:\n",
    "    print(f\"{age_group}: {count}\")\n",
    "\n",
    "print(f\"[TIMING] RDD pipeline: {t3 - t2:.2f} sec\")\n",
    "print(\"====================================================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
